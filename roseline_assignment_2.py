# -*- coding: utf-8 -*-
"""Roseline_Assignment_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/102PQ4pWK7TK1c3_Dej6YbNB4LKeTWvsi
"""

from google.colab import drive
drive.mount('/content/drive')

# Import Libraries

import pickle
import numpy as np
import pandas as pd
from sklearn.svm import SVR
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn import tree, metrics
from sklearn.impute import SimpleImputer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV, KFold, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score

# Data Loading

pd.set_option('display.max_columns', None)

dataset1 = pd.read_csv('/content/drive/My Drive/Roseline/male_players_legacy.csv')

dataset2 = pd.read_csv('/content/drive/My Drive/Roseline/players_22.csv')

ds1 = pd.DataFrame(dataset1)
ds2 = pd.DataFrame(dataset2)

ds1.columns

ds2.columns

ds1.shape

ds2.shape

# Select and keep only the columns in where the proportion of missing values is less than or equal to 0.3 (30%)
ds1 = ds1.loc[:, (ds1.isnull().mean() <= 0.3) | (ds1.isnull().sum() == 0)]
ds2 = ds2.loc[:, (ds2.isnull().mean() <= 0.3) | (ds2.isnull().sum() == 0)]

ds1.shape

ds2.shape

"""**Check for missing values.**"""

nan_ds1 = ds1.isna()
nan_columns_ds1 = nan_ds1.any()
print("\nDataset1:\n")
nan_columns_ds1

nan_ds2 = ds2.isna()
nan_columns_ds2 = nan_ds2.any()
print("\nDataset2:\n")
nan_columns_ds2

missing_ds1 = ds1.isnull().sum()
columns_missing_ds1 = missing_ds1[missing_ds1 > 0].index.tolist()
columns_missing_ds1

missing_ds2 = ds2.isnull().sum()
columns_missing_ds2 = missing_ds2[missing_ds2 > 0].index.tolist()
columns_missing_ds2

# Extract Categorical features
cat_ds1 = ds1.select_dtypes(include=['object']).columns
cat_ds1

# Extract Categorical features
cat_ds2 = ds2.select_dtypes(include=['object']).columns
cat_ds2

# Eliminating columns: dropping the categorical features and column IDs
ds1.drop(cat_ds1, axis=1, inplace=True)
ds2.drop(cat_ds2, axis=1, inplace=True)

ds1.drop(['player_id'], axis=1, inplace=True)
ds2.drop(['sofifa_id'], axis=1, inplace=True)

ds1.shape

ds2.shape

ds1

ds2

missing_ds1 = ds1.isnull().sum()
columns_missing_ds1 = missing_ds1[missing_ds1 > 0].index.tolist()
columns_missing_ds1

missing_ds2 = ds2.isnull().sum()
columns_missing_ds2 = missing_ds2[missing_ds2 > 0].index.tolist()
columns_missing_ds2

# Impute missing values.

imp_ds1 = SimpleImputer(strategy='most_frequent')
imputed_data_ds1 = imp_ds1.fit_transform(ds1)
ds1 = pd.DataFrame(imputed_data_ds1, columns=ds1.columns)

# Check for missing values
missing_ds1 = ds1.isnull().sum()
columns_missing_ds1 = missing_ds1[missing_ds1 > 0].index.tolist()
columns_missing_ds1

# Impute missing values.

# Check for missing values
imp_ds2 = SimpleImputer(strategy='most_frequent')
imputed_data_ds2 = imp_ds2.fit_transform(ds2)
ds2 = pd.DataFrame(imputed_data_ds2, columns=ds2.columns)

missing_ds2 = ds2.isnull().sum()
columns_missing_ds2 = missing_ds2[missing_ds2 > 0].index.tolist()
columns_missing_ds2

"""**Feature Selection**"""

# Check the correlation between each feature and the target variable; overall
corr_mtrx = ds1.corr()
target_corr = corr_mtrx['overall'].drop('overall')

# Select the 10 best features with the highest absolute correlation
features = 15
best_features = target_corr[target_corr > 0.4].abs().nlargest(features).index

# Collect the best correlation feature
selected_features = best_features.tolist()

ds1[selected_features]

selected_features

ds1['overall']

X = ds1[selected_features]
y = ds1['overall']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X = pd.DataFrame(X_scaled, columns=X.columns)

"""**Training and Model Creation**"""

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

x_train.shape, y_test.shape, y_train.shape, x_test.shape

"""**Models**"""

# RandomForest, XGBoost and Gradient Boost Regressors with cv and grid search:
models = {
    'RandomForest': RandomForestRegressor(),
    'XGBoost': XGBRegressor(),
    'GradientBoost': GradientBoostingRegressor()
}

params = {
    'RandomForest': {'n_estimators': [4, 5], 'max_depth': [None, 5]},
    'XGBoost': {'n_estimators': [5, 6], 'learning_rate': [0.01, 0.1]},
    'GradientBoost': {'n_estimators': [4, 6], 'learning_rate': [0.01, 0.1]}
}

for name, model in models.items():
    gs = GridSearchCV(model, params[name], cv=5)
    gs.fit(x_train, y_train)
    # Make predictions using the best model from GridSearchCV
    y_pred = gs.predict(x_test)

    # Evaluate the model
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"\nBest parameters for {name}: {gs.best_params_}")
    print(f"Validation score for {name}: {gs.score(x_test, y_test)}")
    print(f"mean_absolute_error for {name}: {mae}")
    print(f"mean_squared_error for {name}: {mse}",)
    print(f"r2_score for {name}: {r2}\n")

predict_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=None,
    min_samples_split=2,
    min_samples_leaf=1,
    max_features='auto',
    random_state=42
)

# Train the model
predict_model.fit(x_train, y_train)
y_pred = predict_model.predict(x_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("mean_absolute_error:",mae)
print("mean_squared_error:",mse)
print("r2_score:",r2)

# Voting Classifier

decision_tree = DecisionTreeClassifier(random_state=42, criterion='entropy')
knn = KNeighborsClassifier(n_neighbors=10)
svm = SVC(probability=True, random_state=42)

voting_classifier = VotingClassifier(estimators=[
    ('decision_tree', decision_tree),
    ('knn', knn),
    ('svm', svm)
], voting='soft')

for model in (decision_tree, knn, svm,voting_classifier):
  model.fit(x_train,y_train)
  y_pred=model.predict(x_test)
  print(model.__class__.__name__,accuracy_score(y_pred,y_test))

# RandomForestClassifier

rfc=RandomForestClassifier(n_estimators=15, max_depth=4, criterion='entropy')

# Perform cross-validation
cv_scores = cross_val_score(rfc, x_train, y_train, cv=5)
print(f"\nCross-validation scores: {cv_scores}")
print(f"\nMean cross-validation score: {cv_scores.mean()}")

# Fit the model
rfc.fit(x_train,y_train)
y_pred=rfc.predict(x_test)
accuracy_score(y_pred,y_test)
print('\nAccuracy of the model:',accuracy_score(y_pred,y_test))

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("\nmean_absolute_error of the model:",mae)
print("\nmean_squared_error of the model:",mse)
print("\nr2_score of the model:",r2)

# Fine-tune the model (RandomForestClassifier) with GridSearchCV
n_estimators_range = list(range(1, 31))

# Create a parameter grid: map the parameter names to the values that should be searched
param_grid = dict(n_estimators=n_estimators_range)

grid = GridSearchCV(RandomForestClassifier(max_depth=3, criterion='entropy'), param_grid, cv=10, scoring='accuracy')
grid.fit(x_train, y_train)

rfc=RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'], max_depth=3, criterion='entropy')
rfc.fit(x_train,y_train)
y_pred=rfc.predict(x_test)
accuracy_score(y_pred,y_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Examine the best model
print("\ngrid.best_score:",grid.best_score_)
print("\ngrid.best_params:",grid.best_params_)
print("\ngrid.best_estimator:",grid.best_estimator_)
print("\nAccuracy of the best model:", accuracy_score(y_pred,y_test))
print("\nmean_absolute_error of the best model:",mae)
print("\nmean_squared_error of the best model:",mse)
print("\nr2_score of the best model:",r2)

# Correlation between variables in selected_features and the target variable; overall
for name, score in zip(x_train.columns, rfc.feature_importances_):
  print(name, score)

"""### Testing, using players_22

---
"""

test_ds1 = ds2[selected_features]
test_ds2 = ds2['overall']

x_test_22 = test_ds1
y_test_22 = test_ds2

scaler = StandardScaler()
x_test_22_scaled = scaler.fit_transform(x_test_22)
x_test_22 = pd.DataFrame(x_test_22_scaled, columns=x_test_22.columns)

3# RandomForest, XGBoost, Gradient Boost Regressors - testing wit players_22 dataset
models = {
    'RandomForest': RandomForestRegressor(),
    'XGBoost': XGBRegressor(),
    'GradientBoost': GradientBoostingRegressor()
}

params = {
    'RandomForest': {'n_estimators': [4, 5], 'max_depth': [None, 4]},
    'XGBoost': {'n_estimators': [5, 7], 'learning_rate': [0.01, 0.1]},
    'GradientBoost': {'n_estimators': [5, 6], 'learning_rate': [0.01, 0.1]}
}

for name, m in models.items():
    gs = GridSearchCV(m, params[name], cv=5)
    gs.fit(x_train, y_train)
    # Make predictions using the best model from GridSearchCV
    y_pred = gs.predict(x_test_22)

    # Evaluate the model
    mae = mean_absolute_error(y_test_22, y_pred)
    mse = mean_squared_error(y_test_22, y_pred)
    r2 = r2_score(y_test_22, y_pred)

    #print('\nAccuracy: {}'.format(nb_model.score(x_test, y_test)))
    print(f"\nBest parameters for {name}: {gs.best_params_}")
    print(f"Validation score for {name}: {gs.score(x_test_22, y_test_22)}")
    #print()
    print(f"mean_absolute_error for {name}: {mae}")
    print(f"mean_squared_error for {name}: {mse}",)
    print(f"r2_score for {name}: {r2}\n")

"""**Saving Model**"""

filename = 'predictor.pkl'
pickle.dump(predict_model, open(filename, 'wb'))